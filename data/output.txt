2018-12-19 03:07:49 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-12-19 03:07:50 INFO  SparkContext:54 - Running Spark version 2.3.1
2018-12-19 03:07:50 INFO  SparkContext:54 - Submitted application: PopularItems
2018-12-19 03:07:50 INFO  SecurityManager:54 - Changing view acls to: root
2018-12-19 03:07:50 INFO  SecurityManager:54 - Changing modify acls to: root
2018-12-19 03:07:50 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-12-19 03:07:50 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-12-19 03:07:50 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-12-19 03:07:50 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 40943.
2018-12-19 03:07:50 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-12-19 03:07:50 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-12-19 03:07:50 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-12-19 03:07:50 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-12-19 03:07:50 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-7eec4fa4-769a-4e17-8d84-78277fdc536b
2018-12-19 03:07:51 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2018-12-19 03:07:51 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-12-19 03:07:51 INFO  log:192 - Logging initialized @5031ms
2018-12-19 03:07:51 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-12-19 03:07:51 INFO  Server:414 - Started @5229ms
2018-12-19 03:07:51 INFO  AbstractConnector:278 - Started ServerConnector@4dbabb81{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-19 03:07:51 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bf9b994{/jobs,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@261e15cc{/jobs/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16d88fe8{/jobs/job,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@79e5740{/jobs/job/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5178920a{/stages,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38df002{/stages/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c5d6e4b{/stages/stage,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7090c752{/stages/stage/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6728d03d{/stages/pool,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@edb7ca5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1bf69c09{/storage,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6daa7272{/storage/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ca2eec2{/storage/rdd,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@19499da7{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@36705c53{/environment,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@877810d{/environment/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5378aa3f{/executors,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@689b152{/executors/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32aff714{/executors/threadDump,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66467a5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@105b0c04{/static,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2434ae16{/,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4d42340c{/api,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44ecc779{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c15a633{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-12-19 03:07:51 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://spark-master:4040
2018-12-19 03:07:52 INFO  SparkContext:54 - Added file file:/tmp/data/recommendation.py at spark://spark-master:40943/files/recommendation.py with timestamp 1545188872366
2018-12-19 03:07:52 INFO  Utils:54 - Copying /tmp/data/recommendation.py to /tmp/spark-27931e17-e8e1-46b8-878a-43f7f95f39cb/userFiles-173a06d0-ca3a-46a9-99ea-0745e63bd9ee/recommendation.py
2018-12-19 03:07:52 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://spark-master:7077...
2018-12-19 03:07:52 INFO  TransportClientFactory:267 - Successfully created connection to spark-master/172.17.0.7:7077 after 73 ms (0 ms spent in bootstraps)
2018-12-19 03:07:52 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20181219030752-0021
2018-12-19 03:07:52 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20181219030752-0021/0 on worker-20181219023557-172.17.0.10-8881 (172.17.0.10:8881) with 2 core(s)
2018-12-19 03:07:52 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20181219030752-0021/0 on hostPort 172.17.0.10:8881 with 2 core(s), 512.0 MB RAM
2018-12-19 03:07:52 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46601.
2018-12-19 03:07:52 INFO  NettyBlockTransferService:54 - Server created on spark-master:46601
2018-12-19 03:07:52 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-12-19 03:07:52 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20181219030752-0021/0 is now RUNNING
2018-12-19 03:07:53 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, spark-master, 46601, None)
2018-12-19 03:07:53 INFO  BlockManagerMasterEndpoint:54 - Registering block manager spark-master:46601 with 366.3 MB RAM, BlockManagerId(driver, spark-master, 46601, None)
2018-12-19 03:07:53 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, spark-master, 46601, None)
2018-12-19 03:07:53 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, spark-master, 46601, None)
2018-12-19 03:07:53 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1ad99564{/metrics/json,null,AVAILABLE,@Spark}
2018-12-19 03:07:53 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-12-19 03:07:54 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 420.1 KB, free 365.9 MB)
2018-12-19 03:07:54 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.1 KB, free 365.9 MB)
2018-12-19 03:07:54 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on spark-master:46601 (size: 37.1 KB, free: 366.3 MB)
2018-12-19 03:07:54 INFO  SparkContext:54 - Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
2018-12-19 03:07:54 INFO  FileInputFormat:256 - Total input files to process : 1
2018-12-19 03:07:55 INFO  SparkContext:54 - Starting job: collect at /tmp/data/recommendation.py:27
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Registering RDD 3 (distinct at /tmp/data/recommendation.py:18)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Registering RDD 7 (groupByKey at /tmp/data/recommendation.py:21)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Registering RDD 11 (reduceByKey at /tmp/data/recommendation.py:25)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Got job 0 (collect at /tmp/data/recommendation.py:27) with 2 output partitions
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at /tmp/data/recommendation.py:27)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (PairwiseRDD[3] at distinct at /tmp/data/recommendation.py:18), which has no missing parents
2018-12-19 03:07:55 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.6 KB, free 365.8 MB)
2018-12-19 03:07:55 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 365.8 MB)
2018-12-19 03:07:55 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on spark-master:46601 (size: 6.2 KB, free: 366.3 MB)
2018-12-19 03:07:55 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-12-19 03:07:55 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at distinct at /tmp/data/recommendation.py:18) (first 15 tasks are for partitions Vector(0, 1))
2018-12-19 03:07:55 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2018-12-19 03:07:57 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.17.0.10:34974) with ID 0
2018-12-19 03:07:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 172.17.0.10, executor 0, partition 0, PROCESS_LOCAL, 7865 bytes)
2018-12-19 03:07:57 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 172.17.0.10, executor 0, partition 1, PROCESS_LOCAL, 7865 bytes)
2018-12-19 03:07:57 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.17.0.10:45963 with 93.3 MB RAM, BlockManagerId(0, 172.17.0.10, 45963, None)
2018-12-19 03:07:58 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 172.17.0.10:45963 (size: 6.2 KB, free: 93.3 MB)
2018-12-19 03:07:59 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 172.17.0.10:45963 (size: 37.1 KB, free: 93.3 MB)
2018-12-19 03:08:01 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 4455 ms on 172.17.0.10 (executor 0) (1/2)
2018-12-19 03:08:01 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 4421 ms on 172.17.0.10 (executor 0) (2/2)
2018-12-19 03:08:01 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-12-19 03:08:01 INFO  DAGScheduler:54 - ShuffleMapStage 0 (distinct at /tmp/data/recommendation.py:18) finished in 6.505 s
2018-12-19 03:08:01 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-12-19 03:08:01 INFO  DAGScheduler:54 - running: Set()
2018-12-19 03:08:01 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
2018-12-19 03:08:01 INFO  DAGScheduler:54 - failed: Set()
2018-12-19 03:08:01 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (PairwiseRDD[7] at groupByKey at /tmp/data/recommendation.py:21), which has no missing parents
2018-12-19 03:08:01 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 9.8 KB, free 365.8 MB)
2018-12-19 03:08:01 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KB, free 365.8 MB)
2018-12-19 03:08:01 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on spark-master:46601 (size: 6.4 KB, free: 366.3 MB)
2018-12-19 03:08:01 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-12-19 03:08:01 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at groupByKey at /tmp/data/recommendation.py:21) (first 15 tasks are for partitions Vector(0, 1))
2018-12-19 03:08:01 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 2 tasks
2018-12-19 03:08:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 2, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7642 bytes)
2018-12-19 03:08:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 3, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7642 bytes)
2018-12-19 03:08:02 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 172.17.0.10:45963 (size: 6.4 KB, free: 93.3 MB)
2018-12-19 03:08:02 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 172.17.0.10:34974
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 2) in 564 ms on 172.17.0.10 (executor 0) (1/2)
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 3) in 565 ms on 172.17.0.10 (executor 0) (2/2)
2018-12-19 03:08:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-12-19 03:08:02 INFO  DAGScheduler:54 - ShuffleMapStage 1 (groupByKey at /tmp/data/recommendation.py:21) finished in 0.667 s
2018-12-19 03:08:02 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-12-19 03:08:02 INFO  DAGScheduler:54 - running: Set()
2018-12-19 03:08:02 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2018-12-19 03:08:02 INFO  DAGScheduler:54 - failed: Set()
2018-12-19 03:08:02 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (PairwiseRDD[11] at reduceByKey at /tmp/data/recommendation.py:25), which has no missing parents
2018-12-19 03:08:02 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 11.0 KB, free 365.8 MB)
2018-12-19 03:08:02 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KB, free 365.8 MB)
2018-12-19 03:08:02 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on spark-master:46601 (size: 7.3 KB, free: 366.2 MB)
2018-12-19 03:08:02 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-12-19 03:08:02 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 2 (PairwiseRDD[11] at reduceByKey at /tmp/data/recommendation.py:25) (first 15 tasks are for partitions Vector(0, 1))
2018-12-19 03:08:02 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 2 tasks
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 4, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7642 bytes)
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 5, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7642 bytes)
2018-12-19 03:08:02 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 172.17.0.10:45963 (size: 7.3 KB, free: 93.2 MB)
2018-12-19 03:08:02 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 172.17.0.10:34974
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 5) in 251 ms on 172.17.0.10 (executor 0) (1/2)
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 4) in 267 ms on 172.17.0.10 (executor 0) (2/2)
2018-12-19 03:08:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-12-19 03:08:02 INFO  DAGScheduler:54 - ShuffleMapStage 2 (reduceByKey at /tmp/data/recommendation.py:25) finished in 0.303 s
2018-12-19 03:08:02 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-12-19 03:08:02 INFO  DAGScheduler:54 - running: Set()
2018-12-19 03:08:02 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2018-12-19 03:08:02 INFO  DAGScheduler:54 - failed: Set()
2018-12-19 03:08:02 INFO  DAGScheduler:54 - Submitting ResultStage 3 (PythonRDD[14] at collect at /tmp/data/recommendation.py:27), which has no missing parents
2018-12-19 03:08:02 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 7.5 KB, free 365.8 MB)
2018-12-19 03:08:02 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.9 KB, free 365.8 MB)
2018-12-19 03:08:02 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on spark-master:46601 (size: 4.9 KB, free: 366.2 MB)
2018-12-19 03:08:02 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-12-19 03:08:02 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 3 (PythonRDD[14] at collect at /tmp/data/recommendation.py:27) (first 15 tasks are for partitions Vector(0, 1))
2018-12-19 03:08:02 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 2 tasks
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 6, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7653 bytes)
2018-12-19 03:08:02 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 7, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7653 bytes)
2018-12-19 03:08:03 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 172.17.0.10:45963 (size: 4.9 KB, free: 93.2 MB)
2018-12-19 03:08:03 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 172.17.0.10:34974
2018-12-19 03:08:03 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 7) in 816 ms on 172.17.0.10 (executor 0) (1/2)
2018-12-19 03:08:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 6) in 860 ms on 172.17.0.10 (executor 0) (2/2)
2018-12-19 03:08:03 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-12-19 03:08:03 INFO  DAGScheduler:54 - ResultStage 3 (collect at /tmp/data/recommendation.py:27) finished in 0.918 s
2018-12-19 03:08:03 INFO  DAGScheduler:54 - Job 0 finished: collect at /tmp/data/recommendation.py:27, took 8.764781 s
pair: ('54', '56')
recommendation already exists
pair: ('55', '59')
recommendation already exists
pair: ('55', '56')
recommendation already exists
pair: ('56', '59')
recommendation already exists
pair: ('54', '55')
recommendation already exists
pair: ('54', '59')
recommendation already exists
item recommendations done
2018-12-19 03:08:04 INFO  AbstractConnector:318 - Stopped Spark@4dbabb81{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-12-19 03:08:04 INFO  SparkUI:54 - Stopped Spark web UI at http://spark-master:4040
2018-12-19 03:08:04 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-12-19 03:08:04 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-12-19 03:08:04 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-12-19 03:08:04 INFO  MemoryStore:54 - MemoryStore cleared
2018-12-19 03:08:04 INFO  BlockManager:54 - BlockManager stopped
2018-12-19 03:08:04 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-12-19 03:08:04 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-12-19 03:08:04 INFO  SparkContext:54 - Successfully stopped SparkContext
2018-12-19 03:08:05 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-12-19 03:08:05 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-27931e17-e8e1-46b8-878a-43f7f95f39cb/pyspark-46b79945-1148-480e-b3b5-98663a8668eb
2018-12-19 03:08:05 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-27931e17-e8e1-46b8-878a-43f7f95f39cb
2018-12-19 03:08:05 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-2dac92f4-8386-4b16-9609-244bc6c6c24f
